{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from seaborn) (3.9.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.19.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Users/ame/.pyenv/versions/3.9.6/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Users/ame/.pyenv/versions/3.9.6/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import keras\n",
    "from tensorflow.keras.layers import Conv2D, Flatten\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">107648</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">753,543</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m2,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m2,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m18,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m107648\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │       \u001b[38;5;34m753,543\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">777,191</span> (2.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m777,191\u001b[0m (2.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">777,191</span> (2.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m777,191\u001b[0m (2.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Model\n",
    "# CONSTANTS\n",
    "imagesize = 128\n",
    "OUTPUT = 7\n",
    "CLASSES = ['HeadShotHyalomma', 'HeadShotRhipicephalus',\n",
    "        'CenterShotHyalomma', 'CenterShotRhipicephalus',\n",
    "        'CornerShotHyalomma', 'CornerShotRhipicephalus',\n",
    "        'Unidentified']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(imagesize, imagesize, 3)))\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(Conv2D(128, (3,3), 1, activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(OUTPUT, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DENSE_LAYER_ACTIVATION = 'softmax'\n",
    "OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
    "LOSS_METRICS = ['accuracy']\n",
    "CLASS_MODE = 'categorical'\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14574 images belonging to 7 classes.\n",
      "Found 6071 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# preprocessing_function is applied on each image but only after re-sizing & augmentation (resize => augment => pre-process)\n",
    "# Each of the keras.application.resnet* preprocess_input MOSTLY mean BATCH NORMALIZATION (applied on each batch) stabilize the inputs to nonlinear activation functions\n",
    "# Batch Normalization helps in faster convergence\n",
    "# data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# flow_From_directory generates batches of augmented data (where augmentation can be color conversion, etc)\n",
    "# Both train & valid folders must have NUM_CLASSES sub-folders\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "        'datasetB/train',\n",
    "        target_size=(imagesize, imagesize),\n",
    "        # batch_size=BATCH_SIZE_TRAINING,\n",
    "        class_mode=CLASS_MODE,\n",
    "        classes=CLASSES)\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "        'datasetB/dev',\n",
    "        target_size=(imagesize, imagesize),\n",
    "        # batch_size=BATCH_SIZE_VALIDATION,\n",
    "        class_mode=CLASS_MODE,\n",
    "        classes=CLASSES\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 950ms/step - accuracy: 0.4463 - loss: 1.4515 - val_accuracy: 0.5551 - val_loss: 1.1054\n",
      "Epoch 2/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 994ms/step - accuracy: 0.6418 - loss: 0.9540 - val_accuracy: 0.6808 - val_loss: 0.8514\n",
      "Epoch 3/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 1s/step - accuracy: 0.6972 - loss: 0.8077 - val_accuracy: 0.7114 - val_loss: 0.8068\n",
      "Epoch 4/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 994ms/step - accuracy: 0.7569 - loss: 0.6880 - val_accuracy: 0.7472 - val_loss: 0.7103\n",
      "Epoch 5/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 989ms/step - accuracy: 0.7879 - loss: 0.6088 - val_accuracy: 0.7572 - val_loss: 0.6769\n",
      "Epoch 6/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 1s/step - accuracy: 0.8208 - loss: 0.5093 - val_accuracy: 0.7648 - val_loss: 0.6421\n",
      "Epoch 7/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 1s/step - accuracy: 0.8419 - loss: 0.4708 - val_accuracy: 0.7925 - val_loss: 0.5850\n",
      "Epoch 8/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 1s/step - accuracy: 0.8571 - loss: 0.4223 - val_accuracy: 0.8017 - val_loss: 0.5804\n",
      "Epoch 9/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 996ms/step - accuracy: 0.8761 - loss: 0.3714 - val_accuracy: 0.8132 - val_loss: 0.5429\n",
      "Epoch 10/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 1s/step - accuracy: 0.8926 - loss: 0.3267 - val_accuracy: 0.8099 - val_loss: 0.5730\n",
      "Epoch 11/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 1s/step - accuracy: 0.9025 - loss: 0.2962 - val_accuracy: 0.8318 - val_loss: 0.5127\n",
      "Epoch 12/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 1s/step - accuracy: 0.9232 - loss: 0.2451 - val_accuracy: 0.8224 - val_loss: 0.5599\n",
      "Epoch 13/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 991ms/step - accuracy: 0.9250 - loss: 0.2342 - val_accuracy: 0.8310 - val_loss: 0.5379\n",
      "Epoch 14/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 1s/step - accuracy: 0.9390 - loss: 0.1951 - val_accuracy: 0.8213 - val_loss: 0.5812\n",
      "Epoch 15/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 987ms/step - accuracy: 0.9458 - loss: 0.1808 - val_accuracy: 0.8430 - val_loss: 0.5155\n",
      "Epoch 16/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 979ms/step - accuracy: 0.9553 - loss: 0.1498 - val_accuracy: 0.8453 - val_loss: 0.5167\n",
      "Epoch 17/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 972ms/step - accuracy: 0.9637 - loss: 0.1337 - val_accuracy: 0.8371 - val_loss: 0.5640\n",
      "Epoch 18/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 961ms/step - accuracy: 0.9664 - loss: 0.1155 - val_accuracy: 0.8442 - val_loss: 0.5826\n",
      "Epoch 19/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 954ms/step - accuracy: 0.9712 - loss: 0.1028 - val_accuracy: 0.8490 - val_loss: 0.5738\n",
      "Epoch 20/20\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 926ms/step - accuracy: 0.9752 - loss: 0.0919 - val_accuracy: 0.8532 - val_loss: 0.5783\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit(\n",
    "        train_generator,\n",
    "        epochs = NUM_EPOCHS,\n",
    "        validation_data=validation_generator,     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "model_type = \"CNN\"\n",
    "variant = \"VARB\"\n",
    "count = \"00k\"\n",
    "epochs = NUM_EPOCHS\n",
    "result_folder_name = \"cnn\"\n",
    "results_folder = f'results/b/{result_folder_name}/{str(NUM_EPOCHS)}'\n",
    "\n",
    "\n",
    "# Create results folder if it doesn't exist\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize = (15,8)) \n",
    "    \n",
    "# plt.subplot(221)  \n",
    "plt.plot(fit_history.history['accuracy'])  \n",
    "plt.plot(fit_history.history['val_accuracy'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'valid']) \n",
    "plt.savefig(os.path.join(results_folder, 'model-accuracy.png'))\n",
    "plt.close()\n",
    "\n",
    "# plt.subplot(222)  \n",
    "plt.plot(fit_history.history['loss'])  \n",
    "plt.plot(fit_history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'valid']) \n",
    "plt.savefig(os.path.join(results_folder, 'model-loss.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 515ms/step - accuracy: 0.9802 - loss: 0.0779\n",
      "Training Loss: 0.07390842586755753\n",
      "Training Accuracy: 0.9815424680709839\n",
      "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 553ms/step - accuracy: 0.9814 - loss: 0.0747\n",
      "Validation Loss: 0.07390842586755753\n",
      "Validation Accuracy: 0.9815424680709839\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "training_loss, training_accuracy = model.evaluate(train_generator)\n",
    "print(\"Training Loss:\", training_loss)\n",
    "print(\"Training Accuracy:\", training_accuracy)\n",
    "\n",
    "validation_loss, validation_accuracy = model.evaluate(train_generator)\n",
    "print(\"Validation Loss:\", validation_loss)\n",
    "print(\"Validation Accuracy:\", validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ROC AUC\n",
    "with open(os.path.join(results_folder, 'training_validation.txt'), 'w') as f:\n",
    "    f.write(f'training_accuracy: {training_accuracy}\\n')\n",
    "    f.write(f'training_loss: {training_loss}\\n')\n",
    "    f.write(f'validation_accuracy: {validation_accuracy}\\n')\n",
    "    f.write(f'validation_loss: {validation_loss}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5165 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# # Define the model loading function\n",
    "# def load_my_model(model_path):\n",
    "#     return load_model(model_path)\n",
    "\n",
    "# Paths and constants\n",
    "# model_path = 'models/' + name\n",
    "data_folder = 'datasetB/test'\n",
    "\n",
    "# Load the model\n",
    "# model = load_my_model(model_path)\n",
    "\n",
    "# Data generator for the test set\n",
    "testingData = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "testdata = testingData.flow_from_directory(\n",
    "    data_folder,\n",
    "    target_size=(imagesize, imagesize),  # Change this to the input size of your model\n",
    "    class_mode='categorical',  # or 'binary' depending on your model\n",
    "    shuffle=False,\n",
    "    classes=CLASSES\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ame/.pyenv/versions/3.9.6/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 427ms/step - accuracy: 0.8587 - loss: 0.5991\n",
      "Test Loss: 0.4509667158126831\n",
      "Test Accuracy: 0.8880929350852966\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 359ms/step\n",
      "testdata.samples: 5165\n",
      "len(y_true): 5165\n",
      "y_pred:  5165\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "test_loss, test_accuracy = model.evaluate(testdata)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "with open(os.path.join(results_folder, 'test.txt'), 'w') as f:\n",
    "    f.write(f'test_accuracy: {test_accuracy}\\n')\n",
    "    f.write(f'test_loss: {test_loss}\\n')\n",
    "\n",
    "y_true = testdata.classes\n",
    "y_pred_probs = model.predict(testdata, steps=None)\n",
    "\n",
    "print(\"testdata.samples:\", testdata.samples)\n",
    "print(\"len(y_true):\", len(y_true))\n",
    "\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "print(\"y_pred: \", len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 156    2    1    0    8    3    7]\n",
      " [   3  429    1   10    0   19   17]\n",
      " [   2    1  262    7   17    7    1]\n",
      " [   0   26   12  448    1   69   19]\n",
      " [  15    3   24    4  171   15   12]\n",
      " [   2   45   11   66   10  577   23]\n",
      " [  12   26   12   16    9   40 2544]]\n",
      "Accuracy: 0.8880929332042594\n",
      "Precision: 0.8891104507551854\n",
      "Sensitivity (Recall): 0.8880929332042594\n",
      "F1 Score: 0.8891104507551854\n",
      "Results and plots saved to results/b/cnn/20\n"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = precision_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Sensitivity (Recall):\", sensitivity)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate classification report\n",
    "report = classification_report(y_true, y_pred, target_names=CLASSES, output_dict=True)\n",
    "\n",
    "# Save classification report\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv(os.path.join(results_folder, 'classification_report.csv'))\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(y_true, y_pred_probs, multi_class='ovo')\n",
    "\n",
    "# Save ROC AUC\n",
    "with open(os.path.join(results_folder, 'roc_auc.txt'), 'w') as f:\n",
    "    f.write(f'ROC AUC: {roc_auc}\\n')\n",
    "\n",
    "# Calculate sensitivity and specificity for each class\n",
    "sensitivity_per_class = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "\n",
    "# Calculate true negatives, false positives, and specificity for each class\n",
    "tn = []\n",
    "fp = []\n",
    "specificity_per_class = []\n",
    "\n",
    "for i in range(len(CLASSES)):\n",
    "    true_negative = np.sum(conf_matrix) - (np.sum(conf_matrix[i, :]) + np.sum(conf_matrix[:, i]) - conf_matrix[i, i])\n",
    "    false_positive = np.sum(conf_matrix[:, i]) - conf_matrix[i, i]\n",
    "    tn.append(true_negative)\n",
    "    fp.append(false_positive)\n",
    "    specificity_per_class.append(true_negative / (true_negative + false_positive))\n",
    "\n",
    "# Save confusion matrix, sensitivity, specificity, and recall\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=CLASSES, columns=CLASSES)\n",
    "conf_matrix_df.to_csv(os.path.join(results_folder, 'confusion_matrix.csv'))\n",
    "\n",
    "sensitivity_df = pd.DataFrame([sensitivity_per_class], index=['Sensitivity'], columns=CLASSES)\n",
    "sensitivity_df.to_csv(os.path.join(results_folder, 'sensitivity.csv'))\n",
    "\n",
    "specificity_df = pd.DataFrame([specificity_per_class], index=['Specificity'], columns=CLASSES)\n",
    "specificity_df.to_csv(os.path.join(results_folder, 'specificity.csv'))\n",
    "\n",
    "recall_df = pd.DataFrame([sensitivity_per_class], index=['Recall'], columns=CLASSES)\n",
    "recall_df.to_csv(os.path.join(results_folder, 'recall.csv'))\n",
    "\n",
    "# Plot and save confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(os.path.join(results_folder, 'confusion_matrix.png'))\n",
    "plt.close()\n",
    "\n",
    "# Plot and save ROC curve\n",
    "plt.figure()\n",
    "for i, class_name in enumerate(CLASSES):\n",
    "    fpr, tpr, _ = roc_curve(y_true == i, y_pred_probs[:, i])\n",
    "    plt.plot(fpr, tpr, label=f'{class_name} (AUC: {roc_auc_score(y_true == i, y_pred_probs[:, i]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(results_folder, 'roc_curve.png'))\n",
    "plt.close()\n",
    "\n",
    "print(\"Results and plots saved to\", results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-06-2024\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "import math\n",
    "\n",
    "accuracy = accuracy * 100 \n",
    "accuracy = math.floor(accuracy * 100) / 100\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# dd/mm/YY\n",
    "date = \"-\".join(today.strftime(\"%d/%m/%Y\").split(\"/\"))\n",
    "print(date)\n",
    "\n",
    "name = f\"{model_type}_{variant}{count}_{imagesize}x{imagesize}_EP{epochs}_ACCU{accuracy}_{date}.keras\"\n",
    "\n",
    "model.save('models/' + name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
